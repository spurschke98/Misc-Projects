{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import math\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which linear progamming API am I using?\n",
    "# Do not currently have a Gurobi license so puLP it is!  \n",
    "gurobi_lp = False \n",
    "\n",
    "# Variables for event \n",
    "number_sessions =  1\n",
    "max_number_groups = 20 \n",
    "max_group_size = 8\n",
    "number_groups_dict = {1:20 , 2: 20, 3: 20, 4: 20, 5: 20, 6: 20, 7: 20, 8: 20}\n",
    "\n",
    "main_sessions = [i for i in range(1, number_sessions+1)]\n",
    "\n",
    "\n",
    "# When this is true the scheduling conflicts are included, \n",
    "# if changed to false they are removed and everyone is included \n",
    "scheduling_conflicts_on = True\n",
    "\n",
    "\n",
    "# Reporting Outputs \n",
    "write_to_DB = False \n",
    "write_to_excel = True\n",
    "\n",
    "cancelled_contacts = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical and Data Manipulation\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import math\n",
    "import statistics\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Functional Programming\n",
    "from functools import reduce \n",
    "import json \n",
    "import pickle \n",
    "\n",
    "# Copying and Randomization\n",
    "import copy\n",
    "import random\n",
    "\n",
    "# Iteration and Combinations\n",
    "import itertools\n",
    "from itertools import repeat, combinations, permutations, combinations_with_replacement\n",
    "\n",
    "# Collections\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# Excel and Data Handling\n",
    "import xlsxwriter\n",
    "from openpyxl.utils import get_column_letter\n",
    "\n",
    "# Database Connectivity\n",
    "# import pyodbc\n",
    "# import sqlalchemy as db\n",
    "from sqlalchemy import create_engine, MetaData, table, Column, Integer, String\n",
    "\n",
    "# Text Manipulation\n",
    "import re\n",
    "\n",
    "# Date and Time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Progress Bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# String Matching\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "# Word Document Manipulation\n",
    "# from docx import Document\n",
    "# from docx.shared import Cm\n",
    "\n",
    "# Graph Theory\n",
    "import networkx as nx\n",
    "\n",
    "# Linear Programming\n",
    "import pulp\n",
    "from pulp import lpSum, LpMaximize\n",
    "import gurobipy as grb\n",
    "from gurobipy import Model, GRB\n",
    "\n",
    "# System and Process Information\n",
    "import psutil\n",
    "import sys\n",
    "\n",
    "# Excel and Data Handling\n",
    "import xlsxwriter\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(24)\n",
    "\n",
    "# Ignore Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorts the (A) and (F) in the dataframe\n",
    "def sort_group_by_marker(group, session_columns):\n",
    "    # Extract the last 3 characters from each session column\n",
    "    group[session_columns] = group[session_columns].apply(lambda x: x.str[-3:])\n",
    "    \n",
    "    # Create a list of session columns to use for sorting\n",
    "    sort_columns = list(session_columns)\n",
    "    \n",
    "    # Sort the DataFrame by the specified session columns\n",
    "    group = group.sort_values(by=sort_columns, ascending=True)\n",
    "    \n",
    "    # Drop the temporary columns used for sorting\n",
    "    group = group.drop(session_columns, axis=1)\n",
    "    \n",
    "    return group\n",
    "\n",
    "# Print red bold text \n",
    "def print_in_red_and_large(text):\n",
    "    formatted_text = f\"\\033[91m\\033[1m{text}\\033[0m\"\n",
    "    print(formatted_text)\n",
    "\n",
    "\n",
    "# Write a table to the database\n",
    "def create_database_table(table_name, df_name, column_names, engine):\n",
    "    # Create the metadata object\n",
    "    metadata = MetaData()\n",
    "\n",
    "    # Define the table\n",
    "    table = Table(\n",
    "        table_name,\n",
    "        metadata,\n",
    "        Column('ID', Integer, primary_key=True),  # Add an ID column as primary key\n",
    "        *(Column(col, String(255), nullable=False) for col in column_names)\n",
    "    )\n",
    "\n",
    "    # Create the table in the database\n",
    "    metadata.create_all(engine)\n",
    "\n",
    "    # Ensure the group is created\n",
    "    groups = pd.read_sql(\"select * from INFORMATION_SCHEMA.TABLES\", engine)\n",
    "    if table_name in tables['TABLE_NAME'].values:\n",
    "        print(f\"Table '{table_name}' created successfully.\")\n",
    "    else:\n",
    "        print(f\"Error: Table '{table_name}' not found in the database.\")\n",
    "\n",
    "# Changes a name from first_last_A to First Last (A)\n",
    "def convert_name_format(name):\n",
    "    parts = name.split('_')\n",
    "    first_name = parts[0].capitalize()\n",
    "    last_name = parts[1].capitalize()\n",
    "    group = parts[2].upper()\n",
    "    formatted_name = f\"{first_name} {last_name}  ({group})\"\n",
    "    return formatted_name\n",
    "\n",
    "# Define a function to extract the session number\n",
    "def extract_session_number(title):\n",
    "    match = re.search(r'#(\\d+)', title)\n",
    "    if match:\n",
    "        session_number = match.group(1)\n",
    "        return f\"Session {session_number}\"\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data\n",
    "- Data was randomly generated by ChatGPT using the prompt: In table format, give me 120 first and last names (where these are the two columns). first names and last names can be repeated, but no first-last name combination can be repeated. Random words as last names are fine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_db = pd.read_excel(r\"attendee_data.xlsx\", sheet_name= 'all reg')\n",
    "# df_db = pd.read_excel(r\"/Users/summerpurschke/Desktop/attendee_data.xlsx\", sheet_name= 'all reg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "strip whitespace and add CompanyType marker \n",
    "- company types are A or B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Queries \n",
    "df_db['FirstName'] = df_db['FirstName'].str.strip()\n",
    "df_db['LastName'] = df_db['LastName'].str.strip()\n",
    "\n",
    "# Add contact to database to compare\n",
    "condition = df_db['CompanyType'] == 'A'\n",
    "df_db.loc[condition, 'Contact'] = df_db.loc[condition, 'FirstName'].str.lower() + '_' + df_db.loc[condition, 'LastName'].str.lower() + \"_A\"\n",
    "\n",
    "condition = df_db['CompanyType'] == 'B'\n",
    "df_db.loc[condition, 'Contact'] = df_db.loc[condition, 'FirstName'].str.lower() + '_' + df_db.loc[condition, 'LastName'].str.lower() + \"_B\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  remove cancelled people "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_db = df_db[~df_db['Contact'].isin(cancelled_contacts)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scheduling Conflicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create mock data where every ContactID shows every session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range of ContactIDs and the Titles\n",
    "contact_ids = range(1, 120)\n",
    "titles = [f'Session #{i}' for i in range(1, 9)]\n",
    "\n",
    "# Create a list of dictionaries with the desired structure\n",
    "data = []\n",
    "for contact_id in contact_ids:\n",
    "    for title in titles:\n",
    "        data.append({'Title': title, 'ContactId': contact_id})\n",
    "\n",
    "# Create the DataFrame\n",
    "scheduling_conflicts_df_db = pd.DataFrame(data)\n",
    "\n",
    "# scheduling_conflicts_df_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into A and B df\n",
    "groupB_df_db  =  df_db[df_db['CompanyType'] == 'B']\n",
    "groupA_df_db  =  df_db[df_db['CompanyType'] == 'A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a contact field \n",
    "groupA_df_db['Contact'] = groupA_df_db['FirstName'].str.lower() + '_' + groupA_df_db['LastName'].str.lower() + '_A'\n",
    "groupB_df_db['Contact'] = groupB_df_db['FirstName'].str.lower() + '_' + groupB_df_db['LastName'].str.lower() + '_B'\n",
    "\n",
    "# Fold first and last name to lower \n",
    "groupA_df_db['FirstName'] = groupA_df_db['FirstName'].str.lower()\n",
    "groupA_df_db['LastName'] = groupA_df_db['LastName'].str.lower()\n",
    "\n",
    "groupB_df_db['FirstName'] = groupB_df_db['FirstName'].str.lower()\n",
    "groupB_df_db['LastName'] = groupB_df_db['LastName'].str.lower()\n",
    "\n",
    "# Rename to match what I have been using in the following code\n",
    "groupB_df_db = groupB_df_db.rename(columns = {'Asset Class 1': 'Asset Class Theme Pref 1','Asset Class 2': 'Asset Class Theme Pref 2' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupB_df_db['Preference'] = groupB_df_db['Preference'].fillna('')\n",
    "groupB_df_db['NoPreference'] = groupB_df_db['NoPreference'].fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocess preference and no preference names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace whitespace values with None (null)\n",
    "groupB_df_db.loc[groupB_df_db['Preference'].str.strip() == '', 'Preference'] = None\n",
    "\n",
    "if groupB_df_db['Contact'].nunique() == groupB_df_db.shape[0]:\n",
    "    for contact in groupB_df_db['Contact'].unique():\n",
    "        contact_rows = groupB_df_db['Contact'] == contact\n",
    "        if groupB_df_db.loc[contact_rows, 'Preference'].iloc[0] is not None:\n",
    "            # Get the preference values for the current contact\n",
    "            names_string = groupB_df_db.loc[contact_rows, 'Preference'].iloc[0]\n",
    "            names_list = names_string.split(',')\n",
    "\n",
    "            # Strip whitespace, fold to lowercase, and replace spaces with underscores\n",
    "            cleaned_names_list = [name.strip().lower().replace(' ', '_') + '_A' for name in names_list]\n",
    "\n",
    "            # Update the \"Preference\" column with the formatted names\n",
    "            groupB_df_db.loc[contact_rows, 'Preference'] = ','.join(cleaned_names_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace whitespace values with None (null)\n",
    "groupB_df_db.loc[groupB_df_db['NoPreference'].str.strip() == '', 'NoPreference'] = None\n",
    "\n",
    "if groupB_df_db['Contact'].nunique() == groupB_df_db.shape[0]:\n",
    "    for contact in groupB_df_db['Contact'].unique():\n",
    "        contact_rows = groupB_df_db['Contact'] == contact\n",
    "        if groupB_df_db.loc[contact_rows, 'NoPreference'].iloc[0] is not None:\n",
    "            # Get the preference values for the current contact\n",
    "            names_string = groupB_df_db.loc[contact_rows, 'NoPreference'].iloc[0]\n",
    "            names_list = names_string.split(',')\n",
    "\n",
    "            # Strip whitespace, fold to lowercase, and replace spaces with underscores\n",
    "            cleaned_names_list = [name.strip().lower().replace(' ', '_') + '_A' for name in names_list]\n",
    "\n",
    "            # Update the \"Preference\" column with the formatted names\n",
    "            groupB_df_db.loc[contact_rows, 'NoPreference'] = ','.join(cleaned_names_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupA_df_db['Preference'] = groupA_df_db['Preference'].fillna('')\n",
    "\n",
    "# Replace whitespace values with None (null)\n",
    "groupA_df_db.loc[groupA_df_db['Preference'].str.strip() == '', 'Preference'] = None\n",
    "\n",
    "if groupA_df_db['Contact'].nunique() == groupA_df_db.shape[0]:\n",
    "    # print('ok')\n",
    "    for contact in groupA_df_db['Contact'].unique():\n",
    "        contact_rows = groupA_df_db['Contact'] == contact\n",
    "        if groupA_df_db.loc[contact_rows, 'Preference'].iloc[0] is not None:\n",
    "            # Get the preference values for the current contact\n",
    "            names_string = groupA_df_db.loc[contact_rows, 'Preference'].iloc[0]\n",
    "            names_list = names_string.split(',')\n",
    "\n",
    "            # Strip whitespace, fold to lowercase, and replace spaces with underscores\n",
    "            cleaned_names_list = [name.strip().lower().replace(' ', '_') + '_B' for name in names_list]\n",
    "\n",
    "            # Update the \"Preference\" column with the formatted names\n",
    "            groupA_df_db.loc[contact_rows, 'Preference'] = ','.join(cleaned_names_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupB_df_db['NoPreference'] = groupB_df_db['NoPreference'].str.replace('__', '_')\n",
    "groupB_df_db['Preference'] = groupB_df_db['Preference'].str.replace('__', '_')\n",
    "\n",
    "groupA_df_db['NoPreference'] = groupA_df_db['NoPreference'].str.replace('__', '_')\n",
    "groupA_df_db['Preference'] = groupA_df_db['Preference'].str.replace('__', '_')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Remove Cancelled Contacts from prefrences*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in cancelled_contacts:\n",
    "    if name.endswith('_B'):\n",
    "        groupB_df_db['Preference'] = groupB_df_db['Preference'].str.replace(name, '')\n",
    "        groupB_df_db['Preference'] = groupB_df_db['Preference'].str.replace(',,', ',')\n",
    "\n",
    "        groupB_df_db['NoPreference'] = groupB_df_db['NoPreference'].str.replace(name, '')\n",
    "        groupB_df_db['NoPreference'] = groupB_df_db['NoPreference'].str.replace(',,', ',')\n",
    "    elif name.endswith('_A'):\n",
    "        groupA_df_db['Preference'] = groupA_df_db['Preference'].str.replace(name, '')\n",
    "        groupA_df_db['Preference'] = groupA_df_db['Preference'].str.replace(',,', ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scheduling Conflicts DB Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocessing Scheduling conflicts data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_contact_ids = set(groupA_df_db['ContactID'].unique()).intersection(set(groupB_df_db['ContactID'].unique()))\n",
    "if len(set(common_contact_ids)) > 1: raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "if scheduling_conflicts_on:\n",
    "    # list of A and B\n",
    "    A_and_B_contacts = list(set(groupA_df_db['ContactID'].unique()) | set(groupB_df_db['ContactID'].unique()))\n",
    "\n",
    "    # Filter down to only contacts that are relevant\n",
    "    scheduling_conflicts_df = scheduling_conflicts_df_db[scheduling_conflicts_df_db['ContactId'].isin(A_and_B_contacts)]\n",
    "\n",
    "    # Apply the function to create the 'Session' column\n",
    "    # function is in the define functions area\n",
    "    scheduling_conflicts_df['Session'] = scheduling_conflicts_df['Title'].apply(extract_session_number)\n",
    "\n",
    "    # Assign Role column based on where the contactID lives \n",
    "    scheduling_conflicts_df.loc[scheduling_conflicts_df['ContactId'].isin(groupA_df_db['ContactID'].unique()), 'Role'] = 'A'\n",
    "    scheduling_conflicts_df.loc[scheduling_conflicts_df['ContactId'].isin(groupB_df_db['ContactID'].unique()), 'Role'] = 'B'\n",
    "\n",
    "    scheduling_conflicts_df['FirstName'] = np.nan\n",
    "    scheduling_conflicts_df['LastName'] = np.nan\n",
    "\n",
    "    for contact_id in scheduling_conflicts_df['ContactId'].unique():\n",
    "\n",
    "        # A\n",
    "        if scheduling_conflicts_df[scheduling_conflicts_df['ContactId'] == contact_id]['Role'].unique()[0] == 'A':\n",
    "\n",
    "            # Pull First name from A df\n",
    "            firstname = groupA_df_db[groupA_df_db['ContactID'] == contact_id]['FirstName'].values[0]\n",
    "            scheduling_conflicts_df.loc[scheduling_conflicts_df['ContactId'] == contact_id, 'FirstName'] = firstname\n",
    "            # Pull Last name from A data\n",
    "            lastname = groupA_df_db[groupA_df_db['ContactID'] == contact_id]['LastName'].values[0]\n",
    "            scheduling_conflicts_df.loc[scheduling_conflicts_df['ContactId'] == contact_id, 'LastName'] = lastname\n",
    "\n",
    "        # B\n",
    "        elif scheduling_conflicts_df[scheduling_conflicts_df['ContactId'] == contact_id]['Role'].unique()[0] == 'B':\n",
    "            # Pull First name from B data\n",
    "            scheduling_conflicts_df.loc[scheduling_conflicts_df['ContactId'] == contact_id, 'FirstName'] = groupB_df_db[groupB_df_db['ContactID'] == contact_id]['FirstName'].values[0]\n",
    "            # Pull Last name from B data\n",
    "            scheduling_conflicts_df.loc[scheduling_conflicts_df['ContactId'] == contact_id, 'LastName'] = groupB_df_db[groupB_df_db['ContactID'] == contact_id]['LastName'].values[0]\n",
    "\n",
    "    # Rearrange the columns \n",
    "    scheduling_conflicts_df = scheduling_conflicts_df[['FirstName', 'LastName', 'Role', 'Session', 'Title', 'ContactId']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Dictionaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupB = list(groupB_df_db['Contact'].unique())\n",
    "groupA = list(groupA_df_db['Contact'].unique())\n",
    "attendees = list(set(groupB).union(set(groupA)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Mock Data for Preferences\n",
    "- This stays commented out, only used to create or change the mock data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_db['Name'] = df_db['FirstName'].str.strip() + ' ' + df_db['LastName'].str.strip() \n",
    "# groupA_names = list(df_db[df_db['CompanyType'] == 'A']['Name'].unique())\n",
    "# groupB_names = list(df_db[df_db['CompanyType'] == 'B']['Name'].unique())\n",
    "\n",
    "# # Function to assign preferences skewed towards 5 values\n",
    "# def assign_preferences(names_list):\n",
    "#     # Weighted distribution of number of names to choose\n",
    "#     num_choices = random.choices([0, 1, 2, 3, 4, 5], weights=[1, 1, 1, 3, 4, 10])[0]\n",
    "#     if num_choices == 0:\n",
    "#         return ''\n",
    "#     return ', '.join(random.sample(names_list, num_choices))\n",
    "\n",
    "# # Apply function to rows where CompanyType is 'A'\n",
    "# df_db.loc[df_db['CompanyType'] == 'A', 'Preference'] = df_db.loc[df_db['CompanyType'] == 'A'].apply(\n",
    "#     lambda row: assign_preferences(groupB_names), axis=1)\n",
    "\n",
    "# # Apply function to rows where CompanyType is 'B'\n",
    "# df_db.loc[df_db['CompanyType'] == 'B', 'Preference'] = df_db.loc[df_db['CompanyType'] == 'B'].apply(\n",
    "#     lambda row: assign_preferences(groupA_names), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# # Function to assign preferences skewed towards 5 values\n",
    "# def assign_nopreferences(names_list):\n",
    "#     # Weighted distribution of number of names to choose\n",
    "#     num_choices = random.choices([0, 1, 2, 3], weights=[10,10,5,1])[0]\n",
    "#     if num_choices == 0:\n",
    "#         return ''\n",
    "#     return ', '.join(random.sample(names_list, num_choices))\n",
    "\n",
    "# # Apply function to rows where CompanyType is 'B'\n",
    "# df_db.loc[df_db['CompanyType'] == 'B', 'NoPreference'] = df_db.loc[df_db['CompanyType'] == 'B'].apply(\n",
    "#     lambda row: assign_nopreferences(groupB_names), axis=1)\n",
    "\n",
    "\n",
    "# df_db.to_excel(r\"/Users/summerpurschke/Desktop/attendee_data2.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Preferences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove cancelled people from prefs\n",
    "for contact in cancelled_contacts:\n",
    "    groupA_df_db['Preference'] = groupA_df_db['Preference'].str.replace(contact, '')\n",
    "    groupB_df_db['Preference'] = groupB_df_db['Preference'].str.replace(contact, '')\n",
    "    groupB_df_db['NoPreference'] = groupB_df_db['NoPreference'].str.replace(contact, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with 'Contact' as keys and 'Preference' as values\n",
    "groupA_prefs_dict = {}\n",
    "\n",
    "for contact, preference in zip(groupA_df_db['Contact'], groupA_df_db['Preference']):\n",
    "    if preference is not None:\n",
    "        groupA_prefs_dict[contact] = preference.split(',')\n",
    "    if preference is None:\n",
    "        groupA_prefs_dict[contact] = None\n",
    "\n",
    "if set(list(groupA_prefs_dict.keys())) != set(groupA):\n",
    "    raise ValueError('Discrepency with members in pref dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupA_prefs_dict = {key: [value for value in values if value != ''] if values is not None else None for key, values in groupA_prefs_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with 'Contact' as keys and 'Preference' as values\n",
    "groupB_prefs_dict = {}\n",
    "\n",
    "for contact, preference in zip(groupB_df_db['Contact'], groupB_df_db['Preference']):\n",
    "    if preference is not None:\n",
    "        groupB_prefs_dict[contact] = preference.split(',')\n",
    "    if preference is None:\n",
    "        groupB_prefs_dict[contact] = None\n",
    "\n",
    "if set(list(groupB_prefs_dict.keys())) != set(groupB):\n",
    "    raise ValueError('Discrepency with members in pref dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupB_prefs_dict = {key: [value for value in values if value != ''] if values is not None else None for key, values in groupB_prefs_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with 'Contact' as keys and 'Preference' as values\n",
    "groupB_noprefs_dict = {}\n",
    "\n",
    "for contact, preference in zip(groupB_df_db['Contact'], groupB_df_db['NoPreference']):\n",
    "    if preference is not None:\n",
    "        groupB_noprefs_dict[contact] = preference.split(',')\n",
    "    if preference is None:\n",
    "        groupB_noprefs_dict[contact] = None\n",
    "\n",
    "if set(list(groupB_noprefs_dict.keys())) != set(groupB):\n",
    "    raise ValueError('Discrepency with members in pref dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupB_prefs_dict = {key: [value for value in values if value != ''] if values is not None else None for key, values in groupB_noprefs_dict.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create lists of preference pairs\n",
    "##### - Then sort the tuples to ensure consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupA_pref_pairs = [(key, value) for key, values in groupA_prefs_dict.items() if values is not None for value in values]\n",
    "# Sort tuples into ((F,A))\n",
    "temp_list = []\n",
    "for pair in groupA_pref_pairs:\n",
    "    personA = [person for person in pair if person.endswith('_A')][0]\n",
    "    personB = [person for person in pair if person.endswith('_B')][0]\n",
    "    temp_list.append((personA, personB))\n",
    "groupA_pref_pairs = temp_list\n",
    "# Remove tuples where the preferred personB is not in this event \n",
    "groupA_pref_pairs = [pair for pair in groupA_pref_pairs if any(item in groupB for item in pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupB_pref_pairs = [(key, value) for key, values in groupB_prefs_dict.items() if values is not None for value in values]\n",
    "# Sort tuples into ((F,A))\n",
    "temp_list = []\n",
    "for pair in groupB_pref_pairs:\n",
    "    personA = [person for person in pair if person.endswith('_A')][0]\n",
    "    personB = [person for person in pair if person.endswith('_B')][0]\n",
    "    temp_list.append((personA, personB))\n",
    "groupB_pref_pairs = temp_list\n",
    "# Remove tuples where the preferred personB is not in this event \n",
    "groupB_pref_pairs = [pair for pair in groupB_pref_pairs if any(item in groupA for item in pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupB_nopref_pairs = [(key, value) for key, values in groupB_noprefs_dict.items() if values is not None for value in values]\n",
    "# Sort tuples into ((F,A))\n",
    "temp_list = []\n",
    "for pair in groupB_nopref_pairs:\n",
    "    personA = [person for person in pair if person.endswith('_A')][0]\n",
    "    personB = [person for person in pair if person.endswith('_B')][0]\n",
    "    temp_list.append((personA, personB))\n",
    "groupB_nopref_pairs = temp_list\n",
    "# Remove tuples where the preferred personB is not in this event \n",
    "groupB_nopref_pairs = [pair for pair in groupB_nopref_pairs if any(item in groupA for item in pair)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### List of mutual preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_pref_pairs = set(groupA_pref_pairs).intersection(set(groupB_pref_pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Conflicts**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "if scheduling_conflicts_on:\n",
    "    # Separate them based on F or A \n",
    "    scheduling_conflicts_A = scheduling_conflicts_df.loc[scheduling_conflicts_df['Role'] == 'A']\n",
    "    scheduling_conflicts_B = scheduling_conflicts_df.loc[scheduling_conflicts_df['Role'] == 'B']\n",
    "\n",
    "    scheduling_conflicts_A['Contact'] = scheduling_conflicts_A['FirstName'].str.lower().str.strip() + '_' + scheduling_conflicts_A['LastName'].str.lower().str.strip() + '_A'\n",
    "    scheduling_conflicts_B['Contact'] = scheduling_conflicts_B['FirstName'].str.lower().str.strip() + '_' + scheduling_conflicts_B['LastName'].str.lower().str.strip() + '_B'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### These dictionaries are a list of people that ARE Available in each session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "if scheduling_conflicts_on:\n",
    "    # Group A \n",
    "    groupA_scheduling_conflicts = {}\n",
    "    for i in range(1, number_sessions+1):\n",
    "        session_name = f\"Session {i}\"\n",
    "        groupA_scheduling_conflicts [f\"meeting_{i}_conflicts\"] = list(set((scheduling_conflicts_A.loc[scheduling_conflicts_A['Session'] == session_name])['Contact'].to_list()))\n",
    "\n",
    "    # if the contactID is NOT in scheduling_conflicts_A, add the name to every session \n",
    "    groupA_without_availability  = groupA_df_db[groupA_df_db['ContactID'].isin(list(set(groupA_df_db['ContactID'].unique())- set(scheduling_conflicts_A['ContactId'].unique())))]['Contact'].tolist()\n",
    "    for i in range(1, number_sessions+1):\n",
    "        groupA_scheduling_conflicts [f\"meeting_{i}_conflicts\"] = groupA_scheduling_conflicts [f\"meeting_{i}_conflicts\"] + groupA_without_availability\n",
    "\n",
    "    # Group B \n",
    "    groupB_scheduling_conflicts = {}\n",
    "    for i in range(1, number_sessions+1):\n",
    "        session_name = f\"Session {i}\"\n",
    "        groupB_scheduling_conflicts [f\"meeting_{i}_conflicts\"] = list(set((scheduling_conflicts_B.loc[scheduling_conflicts_B['Session'] == session_name])['Contact'].to_list()))\n",
    "\n",
    "    # if the contactID is NOT in scheduling_conflicts_A, add the name to every session \n",
    "    groupB_without_availability  = groupB_df_db[groupB_df_db['ContactID'].isin(list(set(groupB_df_db['ContactID'].unique())- set(scheduling_conflicts_B['ContactId'].unique())))]['Contact'].tolist()\n",
    "    for i in range(1, number_sessions+1):\n",
    "        groupB_scheduling_conflicts [f\"meeting_{i}_conflicts\"] = groupB_scheduling_conflicts [f\"meeting_{i}_conflicts\"] + groupB_without_availability\n",
    "\n",
    "\n",
    "\n",
    "else: \n",
    "    groupA_scheduling_conflicts = {}\n",
    "    for i in range(1, number_sessions+1):\n",
    "        groupA_scheduling_conflicts [f\"meeting_{i}_conflicts\"] = set(groupA)\n",
    "\n",
    "    groupB_scheduling_conflicts = {}\n",
    "    for i in range(1, number_sessions+1):\n",
    "        groupB_scheduling_conflicts [f\"meeting_{i}_conflicts\"] = set(groupB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "# Check for people missing from different sessions\n",
    "for i in range(1, number_sessions+1):\n",
    "    print(len(groupA_scheduling_conflicts[f\"meeting_{i}_conflicts\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n"
     ]
    }
   ],
   "source": [
    "# Check for people missing from different sessions\n",
    "for i in range(1, number_sessions+1):\n",
    "    print(len(groupB_scheduling_conflicts[f\"meeting_{i}_conflicts\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Dictionary of which sessions people ARE available**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "if scheduling_conflicts_on:\n",
    "\n",
    "    # GroupB \n",
    "    groupB_available_sessions ={}\n",
    "    for contact in scheduling_conflicts_B['Contact'].unique().tolist():\n",
    "        groupB_available_sessions[contact] = [int(re.search(r'\\d+', session).group()) for session in scheduling_conflicts_B[scheduling_conflicts_B['Contact'] == contact]['Session']]\n",
    "\n",
    "    # For members of groupB that did not fill out availability - assume available for all \n",
    "    for contact in groupB_without_availability:\n",
    "        groupB_available_sessions[contact] = [i for i in range(1, number_sessions+1)]\n",
    "\n",
    "    # GroupA\n",
    "    groupA_available_sessions ={}\n",
    "    for contact in scheduling_conflicts_A['Contact'].unique().tolist():\n",
    "        groupA_available_sessions[contact] = [int(re.search(r'\\d+', session).group()) for session in scheduling_conflicts_A[scheduling_conflicts_A['Contact'] == contact]['Session']]\n",
    "\n",
    "    # For members of groupA that did not fill out availability - assume available for all \n",
    "    for contact in groupA_without_availability:\n",
    "        groupA_available_sessions[contact] = [i for i in range(1, number_sessions+1)]\n",
    "\n",
    "else:\n",
    "    groupA_available_sessions = {groupA: list(range(1, number_sessions+1)) for personA in groupA}\n",
    "    groupB_available_sessions = {groupB: list(range(1, number_sessions+1)) for personB in groupB}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Group B No Prefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with 'Contact' as keys and 'Preference' as values\n",
    "groupB_no_prefs_dict = {}\n",
    "\n",
    "for contact, preference in zip(groupB_df_db['Contact'], groupB_df_db['NoPreference']):\n",
    "    if preference is not None:\n",
    "        groupB_no_prefs_dict[contact] = preference.split(',')\n",
    "    if preference is None:\n",
    "        groupB_no_prefs_dict[contact] = None\n",
    "\n",
    "if set(list(groupB_no_prefs_dict.keys())) != set(groupB):\n",
    "    raise ValueError('Discrepency with groupB in pref dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupB_no_prefs_pairs = [(key, value) for key, values in groupB_no_prefs_dict.items() if values is not None for value in values]\n",
    "# Sort tuples \n",
    "temp_list = []\n",
    "for pair in groupB_no_prefs_pairs:\n",
    "    personA = [person for person in pair if person.endswith('_A')][0]\n",
    "    personB = [person for person in pair if person.endswith('_B')][0]\n",
    "    temp_list.append((personA,personB))\n",
    "groupB_no_prefs_pairs = temp_list\n",
    "# Remove tuples where the preferred personA is not in this event \n",
    "groupB_no_prefs_pairs = [pair for pair in groupB_no_prefs_pairs if any(item in groupA for item in pair)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Pair Counts**\n",
    "- generate a list of pairs and then sort the tuples for consistent\n",
    "- Blow out to sessions or groups, look at combinations of groups in sessions and then go from there \n",
    "- How many combinations of A/B group structures are there - look at all of these in combination form and then aim to differ the following groups from this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate combinations\n",
    "pair_count_list = list(combinations(attendees, 2))\n",
    "pair_count_list = list(set(pair_count_list)) # remove duplicates\n",
    "\n",
    "\n",
    "# Sort each tuple within the list\n",
    "temp_list = []\n",
    "for pair in pair_count_list:\n",
    "    # If its two people from group A or Group B\n",
    "    if (pair[0] in groupA and pair[1] in groupA) or (pair[0] in groupB and pair[1] in groupB):\n",
    "        temp_list.append((pair[0],pair[1]))\n",
    "    # If its one person from each group \n",
    "    else:\n",
    "\n",
    "        personA = [person for person in pair if person.endswith('_A')][0]\n",
    "        personB = [person for person in pair if person.endswith('_B')][0]\n",
    "        temp_list.append((personA,personB))\n",
    "\n",
    "pair_count_list = temp_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **PersonA / PersonB Pairs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "AB_pairs = []\n",
    "for personA in groupA:\n",
    "    for personB in groupB:\n",
    "        AB_pairs.append((personA,personB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skeleton of Group Assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_groupA_dict = {}\n",
    "number_groupA_dict= {}\n",
    "remaining_groupB_dict = {}\n",
    "number_groupB_dict = {}\n",
    "\n",
    "\n",
    "for i in range(1, 1 + number_sessions):\n",
    "    remaining_groupA_i = groupA_scheduling_conflicts[f\"meeting_{i}_conflicts\"]\n",
    "    number_groupA_i = len(remaining_groupA_i)\n",
    "\n",
    "    remaining_groupA_dict[i] = remaining_groupA_i\n",
    "    number_groupA_dict[i] = number_groupA_i\n",
    "\n",
    "for i in range(1, 1 + number_sessions):\n",
    "    remaining_groupB_i = groupB_scheduling_conflicts[f\"meeting_{i}_conflicts\"]\n",
    "    number_groupB_i = len(remaining_groupB_i)\n",
    "\n",
    "    remaining_groupB_dict[i] = remaining_groupB_i\n",
    "    number_groupB_dict[i] = number_groupB_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Framework for all sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_frameworks = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_than_4A_groups = [i for i in range(1, max_number_groups+1)]  # All groups can have more than 4 at the moment:\n",
    "\n",
    "# group_frameworks = {}\n",
    "\n",
    "for i in main_sessions:\n",
    "    # Use locals() to get the local variable namespace and access the value of the variable\n",
    "    all_groups = range(1, number_groups_dict[i] + 1)\n",
    "    #print(f\"Session {i}: {locals()[f'number_groups_{i}']}\")\n",
    "\n",
    "    # Set up a single dictionary for this session \n",
    "    group_framework = {}\n",
    "\n",
    "    # This is who is available for this session \n",
    "    remaining_A = number_groupA_dict[i]\n",
    "    remaining_B = number_groupB_dict[i]\n",
    "    \n",
    "    #empty list for each group \n",
    "    for group in all_groups:\n",
    "        group_contents = []\n",
    "        group_framework['Group ' + str(group)] = tuple(group_contents)\n",
    "\n",
    "    # Assign group B in a round robin fashion to evenly distribute\n",
    "    while remaining_B >0:\n",
    "        for group in all_groups:\n",
    "            if remaining_B > 0:\n",
    "                group_contents = list(group_framework[f'Group {group}'])\n",
    "                group_contents.append('B')\n",
    "                remaining_B -= 1\n",
    "                group_framework['Group ' + str(group)] = tuple(group_contents)\n",
    "            else: \n",
    "                break\n",
    "\n",
    "    # Assign group A in a round robin fashion to evenly distribute\n",
    "    while remaining_A >0:\n",
    "        for group in all_groups:\n",
    "            assignments = group_framework[f'Group {group}']\n",
    "            # if there is an open seat at the tabe:\n",
    "            if len(assignments)< max_group_size:\n",
    "                # Only proceed if there is an open seat at the group (<8) and dont seat where there is a 4:2 ratio\n",
    "                # if not (assignments.count('A') == 4 and assignments.count('F') == 2) :\n",
    "                if remaining_A > 0:\n",
    "                        group_contents = list(group_framework[f'Group {group}'])\n",
    "                        group_contents.append('A')\n",
    "                        remaining_A -= 1\n",
    "                        group_framework['Group ' + str(group)] = tuple(group_contents)\n",
    "                else: \n",
    "                    break\n",
    "    # Check if all group B members have been assigned\n",
    "    if remaining_B > 0:\n",
    "        print(f'Session {i}: Not all of groupB assigned due to group constraints! {remaining_B} of group B remaining.')\n",
    "    if remaining_A > 0:\n",
    "        print(f'Session {i}: Not all of groupB assigned due to group constraints! {remaining_A} of group A remaining.')\n",
    "\n",
    "\n",
    "    # Sort the values of each key alphabetically\n",
    "    for key in group_framework.keys():\n",
    "        group_framework[key] = tuple(sorted(group_framework[key]))\n",
    "\n",
    "    # Add the group framework for this session to the dictionary\n",
    "    group_frameworks[f'Session {i}'] = group_framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format & Output Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session 1 : All groups are seated? True\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, number_sessions + 1):\n",
    "    session_groups = group_frameworks[f'Session {i}']\n",
    "    print(f'Session {i} : All groups are seated?',\n",
    "        len(list(session_groups.values())) == number_groups_dict[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Quality Check - Check that all groups are utilized in each session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session 1 : All groups are seated? True\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, number_sessions + 1):\n",
    "    session_groups = group_frameworks[f'Session {i}']\n",
    "    print(f'Session {i} : All groups are seated?',\n",
    "        len(list(session_groups.values())) == number_groups_dict[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format & Output Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create dataframe from dictionary\n",
    "group_frameworks_df = pd.DataFrame(group_frameworks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Ratio Value Counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Session 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2/3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2/4</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3/4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Session 1\n",
       "2/3          3\n",
       "2/4         15\n",
       "3/4          2"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary to store the counts for each ratio\n",
    "ratio_counts = {}\n",
    "\n",
    "# Iterate over sessions and groups\n",
    "\n",
    "for session, groups in group_frameworks.items():\n",
    "    for group, contents in groups.items():\n",
    "        # Calculate the ratio of A to B for each group\n",
    "        ratio = f\"{contents.count('A')}/{contents.count('B')}\"\n",
    "        \n",
    "        # Increment the count in the dictionary\n",
    "        ratio_counts.setdefault(ratio, {}).setdefault(session, 0)\n",
    "        ratio_counts[ratio][session] += 1\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "df_counts = pd.DataFrame(ratio_counts)\n",
    "\n",
    "# Transpose the DataFrame for the desired format\n",
    "ratio_counts_df = df_counts.T.fillna(0).astype(int).sort_index()\n",
    "\n",
    "# Rearrange to be chronological\n",
    "ratio_counts_df = ratio_counts_df[[f'Session {i}' for i in range(1, number_sessions+1)]]\n",
    "\n",
    "# print\n",
    "ratio_counts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the number of groups for each Session "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number_groups_df = pd.DataFrame(number_groups_dict.items(), columns=['Session', 'Number of groups']).set_index('Session').T\n",
    "# number_groups_df.columns = ratio_counts_df.columns\n",
    "\n",
    "# # Add group counts to ratio \n",
    "# ratio_counts_df = pd.concat([number_groups_df, ratio_counts_df])\n",
    "\n",
    "# # Set secondary column index as Number of groups \n",
    "# ratio_counts_df = ratio_counts_df.T.reset_index().rename(columns = {'index':'Session'}).set_index(['Session', 'Number of groups']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataFrame for Total counts per Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary to store the counts\n",
    "counts_dict = {}\n",
    "\n",
    "# Iterate through sessions and groups\n",
    "for session, groups in group_frameworks.items():\n",
    "    session_counts = {'GroupA': 0, 'GroupB': 0}\n",
    "    # print(session_counts)\n",
    "    \n",
    "    for group, contents in groups.items():\n",
    "\n",
    "        # Count the occurrences of 'A' and 'B' in each group\n",
    "        session_counts['GroupA'] += contents.count('A')\n",
    "        session_counts['GroupB'] += contents.count('B')\n",
    "\n",
    "\n",
    "    # Store the counts in the dictionary\n",
    "    counts_dict[(session, 'GroupA')] = session_counts['GroupA']\n",
    "    counts_dict[(session, 'GroupB')] = session_counts['GroupB']\n",
    "    \n",
    "data = counts_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Session 1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Role</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GroupA</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GroupB</th>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Session 1\n",
       "Role             \n",
       "GroupA         42\n",
       "GroupB         77"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a dictionary to store the counts\n",
    "data = {}\n",
    "\n",
    "# Iterate through sessions and groups\n",
    "for session, groups in group_frameworks.items():\n",
    "    session_counts = {'GroupA': 0, 'GroupB': 0}\n",
    "    \n",
    "    for group, contents in groups.items():\n",
    "        # Count the occurrences of 'A' and 'F' in each group\n",
    "        session_counts['GroupA'] += contents.count('A')\n",
    "        session_counts['GroupB'] += contents.count('B')\n",
    "\n",
    "    # Store the counts in the dictionary\n",
    "    data[(session, 'GroupA')] = session_counts['GroupA']\n",
    "    data[(session, 'GroupB')] = session_counts['GroupB']\n",
    "\n",
    "\n",
    "# Create a dataframe from the dictionary\n",
    "AB_counts_df = pd.DataFrame.from_dict(data, orient='index', columns=['Value'])\n",
    "\n",
    "# Rename the row and column indices\n",
    "AB_counts_df.index.names = ['Session']\n",
    "\n",
    "# Print the dataframe\n",
    "AB_counts_df = AB_counts_df.reset_index()\n",
    "\n",
    "AB_counts_df['Session'] = AB_counts_df['Session'].apply(str)\n",
    "AB_counts_df[['Session', 'Role']] = AB_counts_df['Session'].str.split(',', expand=True)\n",
    "AB_counts_df['Session'] = AB_counts_df['Session'].str[2:-1].str.strip()\n",
    "AB_counts_df['Role'] = AB_counts_df['Role'].str[2:-2].str.strip()\n",
    "AB_counts_df = AB_counts_df.rename(columns = {'Value':'Count'})\n",
    "\n",
    "# Set index as Session and Role\n",
    "AB_counts_df = AB_counts_df.set_index(['Session', 'Role'])\n",
    "\n",
    "# pivot the table so that Sessions are across the top and people are rows\n",
    "AB_counts_df = AB_counts_df.reset_index().pivot(index='Role', columns='Session', values='Count')\n",
    "\n",
    "# filter to only rows that have 'GroupA' or 'GroupB'\n",
    "AB_counts_df = AB_counts_df[AB_counts_df.index.isin(['GroupA', 'GroupB'])]\n",
    "\n",
    "# remove the name of the columns index\n",
    "AB_counts_df.columns.name = None\n",
    "\n",
    "# Preview df\n",
    "AB_counts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Assigments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_group_assignments = {}\n",
    "for session in main_sessions:\n",
    "    main_group_assignments[f'Session {session}'] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up LP Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define LP Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gurobi_lp == True: \n",
    "    # Create a Gurobi model\n",
    "    lp_problem = Model(\"GroupAssignmentsMainSessions\")\n",
    "else: \n",
    "    lp_problem = pulp.LpProblem(\"GroupAssignmentsMainSessions\", pulp.LpMaximize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seated \n",
    "- One variable for each person in each session as each group\n",
    "- Binary: 0 (person is not seated at this group in this session) or 1 (person is seated at this group in this session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gurobi_lp == True:   \n",
    "    seated_vars = {(person, session, group, 'A'): lp_problem.addVar(vtype=GRB.BINARY, name=f\"Seated{person}_{session}_{group}\")\n",
    "                for person in groupA\n",
    "                for session in groupA_available_sessions[person] #main_sessions\n",
    "                for group in range(1, number_groups_dict[session]+1)}\n",
    "\n",
    "    # Update the dictionary with group B\n",
    "    seated_vars.update({(person, session, group, 'B'): lp_problem.addVar(vtype=GRB.BINARY, name=f\"Seated{person}_{session}_{group}\")\n",
    "                        for person in groupB\n",
    "                        for session in groupB_available_sessions[person] #main_sessions\n",
    "                        for group in range(1, number_groups_dict[session]+1)} )\n",
    "else:\n",
    "    seated_vars = {(person, session, group, 'A'): pulp.LpVariable(f\"Seated{person}_{session}_{group}\", cat='Binary')\n",
    "                for person in groupA\n",
    "                for session in groupA_available_sessions[person] #main_sessions\n",
    "                for group in range(1, number_groups_dict[session]+1) if session in groupA_available_sessions[person]}\n",
    "\n",
    "    # Update the dictionary with group B\n",
    "    seated_vars.update({(person, session, group, 'B'): pulp.LpVariable(f\"Seated{person}_{session}_{group}\", cat='Binary')\n",
    "                        for person in groupB\n",
    "                        for session in groupB_available_sessions[person] #main_sessions\n",
    "                        for group in range(1, number_groups_dict[session]+1) })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Session group Pairs\n",
    "- One variable for each pair for each session and group\n",
    "- Binary: 0(this pair is not seated together in this session, at this group) or 1 (this pair is seated together at this group in this session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gurobi_lp == True:\n",
    "    # Create integer decision variables for pair counts\n",
    "    group_session_pair_vars = {(pair, session, group): lp_problem.addVar(vtype=GRB.BINARY, name=f\"pair_session_tabe{ pair, session, group}\")\n",
    "        for pair in pair_count_list for session in main_sessions for group in range(1, number_groups_dict[session]+1)}\n",
    "else:\n",
    "    # Create integer decision variables for pair counts using PuLP\n",
    "    group_session_pair_vars = {(pair, session, group): pulp.LpVariable(f\"pair_session_tabe{ pair, session, group}\", cat='Binary')\n",
    "        for pair in pair_count_list for session in main_sessions for group in range(1, number_groups_dict[session]+1)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign group Session Pair Variable values based on seated variable values \n",
    "- Value should be 1 if both seated vars for this pair, session, and group are also 1 (else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gurobi_lp:\n",
    "    # For AA Pairs \n",
    "    for pair in [pair for pair in pair_count_list if pair[0].endswith('A') and pair[1].endswith('A')]:\n",
    "        for session in main_sessions:\n",
    "            if session in groupA_available_sessions[pair[0]] and session in groupA_available_sessions[pair[1]]:\n",
    "                for group in range(1, number_groups_dict[session]+1):\n",
    "                    lp_problem.addConstr(group_session_pair_vars[(pair[0], pair[1]), session, group] >= seated_vars[pair[0], session, group, 'A'] + seated_vars[pair[1], session, group, 'A'] - 1)\n",
    "                    lp_problem.addConstr(group_session_pair_vars[(pair[0], pair[1]), session, group] <= seated_vars[pair[0], session, group, 'A'])\n",
    "                    lp_problem.addConstr(group_session_pair_vars[(pair[0], pair[1]), session, group] <= seated_vars[pair[1], session, group, 'A'])\n",
    "    # For BB Pairs \n",
    "    for pair in [pair for pair in pair_count_list if pair[0].endswith('B') and pair[1].endswith('B')]:\n",
    "        for session in main_sessions:\n",
    "            if session in groupB_available_sessions[pair[0]] and session in groupB_available_sessions[pair[1]]:\n",
    "                for group in range(1, number_groups_dict[session]+1):\n",
    "                    lp_problem.addConstr(group_session_pair_vars[(pair[0], pair[1]), session, group] >= seated_vars[pair[0], session, group, 'B'] + seated_vars[pair[1], session, group, 'B'] - 1)\n",
    "                    lp_problem.addConstr(group_session_pair_vars[(pair[0], pair[1]), session, group] <= seated_vars[pair[0], session, group, 'B'])\n",
    "                    lp_problem.addConstr(group_session_pair_vars[(pair[0], pair[1]), session, group] <= seated_vars[pair[1], session, group, 'B'])\n",
    "    # For AB Pairs \n",
    "    for pair in [pair for pair in pair_count_list if pair[0].endswith('A') and pair[1].endswith('B')]:\n",
    "        for session in main_sessions:\n",
    "            if session in groupA_available_sessions[pair[0]] and session in groupB_available_sessions[pair[1]]:\n",
    "                for group in range(1, number_groups_dict[session]+1):\n",
    "                    lp_problem.addConstr(group_session_pair_vars[(pair[0], pair[1]), session, group] >= seated_vars[pair[0], session, group, 'A'] + seated_vars[pair[1], session, group, 'B'] - 1)\n",
    "                    lp_problem.addConstr(group_session_pair_vars[(pair[0], pair[1]), session, group] <= seated_vars[pair[0], session, group, 'A'])\n",
    "                    lp_problem.addConstr(group_session_pair_vars[(pair[0], pair[1]), session, group] <= seated_vars[pair[1], session, group, 'B'])\n",
    "else:\n",
    "    # For AA Pairs \n",
    "    for pair in [pair for pair in pair_count_list if pair[0].endswith('A') and pair[1].endswith('A')]:\n",
    "        for session in main_sessions:\n",
    "            for group in range(1, number_groups_dict[session]+1):\n",
    "                lp_problem += group_session_pair_vars[(pair[0], pair[1]), session, group] >= seated_vars[pair[0], session, group, 'A'] + seated_vars[pair[1], session, group, 'A'] - 1\n",
    "                lp_problem += group_session_pair_vars[(pair[0], pair[1]), session, group] <= seated_vars[pair[0], session, group, 'A']\n",
    "                lp_problem += group_session_pair_vars[(pair[0], pair[1]), session, group] <= seated_vars[pair[1], session, group, 'A']\n",
    "    # For BB Pairs \n",
    "    for pair in [pair for pair in pair_count_list if pair[0].endswith('B') and pair[1].endswith('B')]:\n",
    "        for session in main_sessions:\n",
    "            for group in range(1, number_groups_dict[session]+1):\n",
    "                lp_problem += group_session_pair_vars[(pair[0], pair[1]), session, group] >= seated_vars[pair[0], session, group, 'B'] + seated_vars[pair[1], session, group, 'B'] - 1\n",
    "                lp_problem += group_session_pair_vars[(pair[0], pair[1]), session, group] <= seated_vars[pair[0], session, group, 'B']\n",
    "                lp_problem += group_session_pair_vars[(pair[0], pair[1]), session, group] <= seated_vars[pair[1], session, group, 'B']\n",
    "    # For AB Pairs \n",
    "    for pair in [pair for pair in pair_count_list if pair[0].endswith('A') and pair[1].endswith('B')]:\n",
    "        for session in main_sessions:\n",
    "            for group in range(1, number_groups_dict[session]+1):\n",
    "                lp_problem += group_session_pair_vars[(pair[0], pair[1]), session, group] >= seated_vars[pair[0], session, group, 'A'] + seated_vars[pair[1], session, group, 'B'] - 1\n",
    "                lp_problem += group_session_pair_vars[(pair[0], pair[1]), session, group] <= seated_vars[pair[0], session, group, 'A']\n",
    "                lp_problem += group_session_pair_vars[(pair[0], pair[1]), session, group] <= seated_vars[pair[1], session, group, 'B']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each Attendee must be sat 1 time in each session - no more and no less - for the sessions that they are available\n",
    "- This combined with the constraint of how many people per session will satisfy the constraint of scheduling conflicts\n",
    "- If these are all seated there is no room for people that are not available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gurobi_lp == True: \n",
    "    # Constraints for each A being seated once in a session\n",
    "    for personA in groupA:\n",
    "        for session in list(set(groupA_available_sessions[personA]).intersection(set(main_sessions))):\n",
    "            lp_problem.addConstr(grb.quicksum(seated_vars[(personA, session, group, 'A')] for group in range(1, number_groups_dict[session] + 1)) == 1)\n",
    "    for personB in groupB:\n",
    "        for session in list(set(groupB_available_sessions[personB]).intersection(set(main_sessions))):\n",
    "            lp_problem.addConstr(grb.quicksum(seated_vars[(personB, session, group, 'B')] for group in range(1, number_groups_dict[session] + 1)) == 1)\n",
    "\n",
    "else:\n",
    "    # Constraints for each A being seated once in a session using PuLP\n",
    "    for personA in groupA:\n",
    "        for session in list(set(groupA_available_sessions[personA]).intersection(set(main_sessions))):\n",
    "            lp_problem += pulp.lpSum(seated_vars[(personA, session, group, 'A')] for group in range(1, number_groups_dict[session] + 1)) == 1\n",
    "    for personB in groupB:\n",
    "        for session in list(set(groupB_available_sessions[personB]).intersection(set(main_sessions))):\n",
    "            lp_problem += pulp.lpSum(seated_vars[(personB, session, group, 'B')] for group in range(1, number_groups_dict[session] + 1)) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No pair can sit together more than N time in the main sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gurobi_lp:\n",
    "    for pair in pair_count_list:\n",
    "        lp_problem.addConstr(grb.quicksum([group_session_pair_vars[var] for var in group_session_pair_vars if var[0] == pair]) <= 3)\n",
    "else:\n",
    "    for pair in pair_count_list:\n",
    "        lp_problem += pulp.lpSum([group_session_pair_vars[var] for var in group_session_pair_vars if var[0] == pair]) <= 3, f\"UpperBoundConstraint_{pair}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of Group A members and Group B members at each group need to follow the previously identified framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gurobi_lp == True: \n",
    "    # Constraints for A and B at each group in each session\n",
    "    for session in main_sessions:\n",
    "        for group in range(1, number_groups_dict[session] + 1):\n",
    "            assignments = group_frameworks[f'Session {session}'][f'Group {group}']\n",
    "            count_A = assignments.count('A')\n",
    "            count_B = assignments.count('B')\n",
    "\n",
    "            # Constraints for A at this group in this session\n",
    "            lp_problem.addConstr(grb.quicksum(seated_vars[(person, session, group, 'A')] for person in groupA_scheduling_conflicts[f'meeting_{session}_conflicts'])== count_A)\n",
    "\n",
    "            # Constraints for B at this group in this session\n",
    "            lp_problem.addConstr(grb.quicksum(seated_vars[(person, session, group, 'B')] for person in groupB_scheduling_conflicts[f'meeting_{session}_conflicts'])== count_B)\n",
    "\n",
    "else:\n",
    "    # Constraints for A and B at each group in each session using PuLP\n",
    "    for session in main_sessions:\n",
    "        for group in range(1, number_groups_dict[session] + 1):\n",
    "            assignments = group_frameworks[f'Session {session}'][f'Group {group}']\n",
    "            count_A = assignments.count('A')\n",
    "            count_B = assignments.count('B')\n",
    "\n",
    "            # Constraints for A at this group in this session\n",
    "            lp_problem += pulp.lpSum(seated_vars[(person, session, group, 'A')] for person in groupA_scheduling_conflicts[f'meeting_{session}_conflicts']) == count_A\n",
    "\n",
    "            # Constraints for B at this group in this session\n",
    "            lp_problem += pulp.lpSum(seated_vars[(person, session, group, 'B')] for person in groupB_scheduling_conflicts[f'meeting_{session}_conflicts'])== count_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pairs that do not want to be seated together are not seated together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair in groupB_nopref_pairs:\n",
    "    lp_problem.addConstr(grb.quicksum([group_session_pair_vars[var] for var in group_session_pair_vars if var[0] == pair]) == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Objective Function(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_max_mutual_prefs:          1\n",
      "weight_max_groupB_prefs:          0.7\n",
      "weight_max_groupA_prefs:          0.5\n",
      "weight_min_groupB_no_prefs:       0.5\n"
     ]
    }
   ],
   "source": [
    "weight_max_mutual_prefs = 1\n",
    "weight_max_groupB_prefs = 0.7\n",
    "weight_max_groupA_prefs = .5\n",
    "weight_min_groupB_no_prefs = 0.5\n",
    "\n",
    "print('weight_max_mutual_prefs:         ', weight_max_mutual_prefs) \n",
    "print('weight_max_groupB_prefs:         ', weight_max_groupB_prefs)\n",
    "print('weight_max_groupA_prefs:         ', weight_max_groupA_prefs)\n",
    "print('weight_min_groupB_no_prefs:      ', weight_min_groupB_no_prefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These objectives only get added if the weights are > 0 (or the minimization weights are <0)\n",
    "if gurobi_lp: \n",
    "\n",
    "    # Maximize the number of joint-preferences satisfied\n",
    "    if abs(weight_max_mutual_prefs) >0:\n",
    "        print('Mutal Prefs goal applied')\n",
    "        lp_problem.setObjective(\\\n",
    "            grb.quicksum(group_session_pair_vars[var] for var in group_session_pair_vars if var[0] in mutual_pref_pairs),\n",
    "            sense=GRB.MAXIMIZE)\n",
    "    \n",
    "    # Maximize the number of groupB preferences satisfied\n",
    "    if abs(weight_max_groupB_prefs) >0:\n",
    "        print('GroupB Prefs goal applied')\n",
    "        lp_problem.setObjectiveN(\n",
    "            grb.quicksum(group_session_pair_vars[var] for var in group_session_pair_vars if var[0] in groupB_pref_pairs), \n",
    "            index = 5, \n",
    "            # priority = 1,\n",
    "            weight=weight_max_groupB_prefs,\n",
    "            name=\"Max GroupB Prefs\" )\n",
    "    \n",
    "    # Maximize the number of groupA preferences satisfied\n",
    "    if abs(weight_max_groupA_prefs) >0 :\n",
    "        print('GroupA Prefs goal applied')\n",
    "        lp_problem.setObjectiveN(\n",
    "            grb.quicksum(group_session_pair_vars[var] for var in group_session_pair_vars if var[0] in groupA_pref_pairs), \n",
    "            index = 4, \n",
    "            # priority = 2,\n",
    "            weight = weight_max_groupA_prefs,\n",
    "            name=\"Max GroupA Prefs\" )\n",
    "\n",
    "    # Minimize the number  of no-seated preferences\n",
    "    if abs(weight_min_groupB_no_prefs) >0 :\n",
    "        print('Group B no matches goal applied')\n",
    "        lp_problem.setObjectiveN(\n",
    "            grb.quicksum(group_session_pair_vars[var] for var in group_session_pair_vars if var[0] in groupB_nopref_pairs),\n",
    "            index = 1,\n",
    "            # priority = 2,\n",
    "            weight = weight_min_groupB_no_prefs , \n",
    "            name = 'Min GroupB No prefs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutal Prefs goal applied\n",
      "Group B Prefs goal applied\n",
      "Group A Prefs goal applied\n",
      "Group B no matches goal applied\n"
     ]
    }
   ],
   "source": [
    "if not gurobi_lp: \n",
    "\n",
    "    # Maximize the number of joint-preferences satisfied\n",
    "    if abs(weight_max_mutual_prefs) > 0:\n",
    "        print('Mutal Prefs goal applied')\n",
    "        lp_problem += pulp.lpSum(group_session_pair_vars[var] for var in group_session_pair_vars if var[0] in mutual_pref_pairs)\n",
    "    \n",
    "    # Maximize the number of B preferences satisfied\n",
    "    if abs(weight_max_groupB_prefs) > 0:\n",
    "        print('Group B Prefs goal applied')\n",
    "        lp_problem += pulp.lpSum(group_session_pair_vars[var] for var in group_session_pair_vars if var[0] in groupB_pref_pairs) * weight_max_groupB_prefs\n",
    "    \n",
    "    # Maximize the number of A preferences satisfied\n",
    "    if abs(weight_max_groupA_prefs) > 0:\n",
    "        print('Group A Prefs goal applied')\n",
    "        lp_problem += pulp.lpSum(group_session_pair_vars[var] for var in group_session_pair_vars if var[0] in groupA_pref_pairs) * weight_max_groupA_prefs\n",
    "\n",
    "    # Minimize the number  of no-seated preferences\n",
    "    if abs(weight_min_groupB_no_prefs) > 0:\n",
    "        print('Group B no matches goal applied')\n",
    "        lp_problem += pulp.lpSum(group_session_pair_vars[var] for var in group_session_pair_vars if var[0] in groupB_nopref_pairs) * weight_min_groupB_no_prefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the CBC MILP Solver \n",
      "Version: 2.10.3 \n",
      "Build Date: Dec 15 2019 \n",
      "\n",
      "command line - /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pulp/solverdir/cbc/osx/64/cbc /var/folders/6f/4qxwc5z945bfn2tp69gkk7200000gn/T/005e44ce62af481d8b3e85ae2249b028-pulp.mps -max -timeMode elapsed -branch -printingOptions all -solution /var/folders/6f/4qxwc5z945bfn2tp69gkk7200000gn/T/005e44ce62af481d8b3e85ae2249b028-pulp.sol (default strategy 1)\n",
      "At line 2 NAME          MODEL\n",
      "At line 3 ROWS\n",
      "At line 428445 COLUMNS\n",
      "At line 1842167 RHS\n",
      "At line 2270608 BOUNDS\n",
      "At line 2413410 ENDATA\n",
      "Problem MODEL has 428440 rows, 142801 columns and 1128120 elements\n",
      "Coin0008I MODEL read with 0 errors\n",
      "Option for timeMode changed from cpu to elapsed\n",
      "Continuous objective value is 0 - 1.09 seconds\n",
      "Cgl0003I 0 fixed, 0 tightened bounds, 16560 strengthened rows, 0 substitutions\n",
      "Cgl0003I 0 fixed, 0 tightened bounds, 17482 strengthened rows, 0 substitutions\n",
      "Cgl0003I 0 fixed, 0 tightened bounds, 6127 strengthened rows, 0 substitutions\n",
      "Cgl0003I 0 fixed, 0 tightened bounds, 12702 strengthened rows, 0 substitutions\n",
      "Cgl0003I 0 fixed, 0 tightened bounds, 9437 strengthened rows, 0 substitutions\n",
      "Cgl0003I 0 fixed, 0 tightened bounds, 6447 strengthened rows, 0 substitutions\n",
      "Cgl0003I 0 fixed, 0 tightened bounds, 6749 strengthened rows, 0 substitutions\n",
      "Cgl0003I 0 fixed, 0 tightened bounds, 7931 strengthened rows, 0 substitutions\n",
      "Cgl0003I 0 fixed, 0 tightened bounds, 8149 strengthened rows, 0 substitutions\n",
      "Cgl0004I processed model has 428440 rows, 142800 columns (142800 integer (142800 of which binary)) and 1219704 elements\n",
      "Cbc0045I No integer variables out of 142800 objects (142800 integer) have costs\n",
      "Cbc0045I branch on satisfied N create fake objective Y random cost Y\n",
      "Cbc0038I Initial state - 238 integers unsatisfied sum - 119\n",
      "Cbc0038I Pass   1: (517.26 seconds) suminf.  118.58333 (306) obj. 0 iterations 759\n",
      "Cbc0038I Pass   2: (527.73 seconds) suminf.  118.05556 (341) obj. 0 iterations 1100\n",
      "Cbc0038I Pass   3: (529.55 seconds) suminf.  117.14411 (411) obj. 0 iterations 225\n",
      "Cbc0038I Pass   4: (531.67 seconds) suminf.  116.21471 (477) obj. 0 iterations 232\n",
      "Cbc0038I Pass   5: (538.50 seconds) suminf.  114.58628 (611) obj. 0 iterations 419\n",
      "Cbc0038I Pass   6: (542.41 seconds) suminf.  113.85907 (666) obj. 0 iterations 243\n",
      "Cbc0038I Pass   7: (564.83 seconds) suminf.  104.90121 (1008) obj. 0 iterations 1347\n",
      "Cbc0038I Pass   8: (588.68 seconds) suminf.  101.00924 (1279) obj. 0 iterations 919\n",
      "Cbc0038I Pass   9: (605.90 seconds) suminf.   99.32889 (1394) obj. 0 iterations 553\n",
      "Cbc0038I Pass  10: (618.99 seconds) suminf.   98.55218 (1443) obj. 0 iterations 368\n",
      "Cbc0038I Pass  11: (2383.36 seconds) suminf.   99.36221 (1397) obj. 0 iterations 1070\n",
      "Cbc0038I Pass  12: (2393.42 seconds) suminf.   99.30761 (1392) obj. 0 iterations 246\n",
      "Cbc0038I Pass  13: (2416.73 seconds) suminf.   98.53600 (1450) obj. 0 iterations 515\n",
      "Cbc0038I Pass  14: (2447.89 seconds) suminf.   99.35684 (1397) obj. 0 iterations 796\n",
      "Cbc0038I Pass  15: (2596.44 seconds) suminf.  168.32999 (659) obj. 0 iterations 6959\n",
      "Cbc0038I Pass  16: (2628.04 seconds) suminf.  113.25970 (530) obj. 0 iterations 3121\n",
      "Cbc0038I Pass  17: (2641.59 seconds) suminf.  110.33221 (773) obj. 0 iterations 628\n",
      "Cbc0038I Pass  18: (2675.67 seconds) suminf.  102.09886 (1146) obj. 0 iterations 1235\n",
      "Cbc0038I Pass  19: (2703.48 seconds) suminf.   99.36397 (1325) obj. 0 iterations 711\n",
      "Cbc0038I Pass  20: (2738.28 seconds) suminf.   97.68587 (1434) obj. 0 iterations 615\n",
      "Cbc0038I Pass  21: (2769.91 seconds) suminf.   98.52027 (1383) obj. 0 iterations 875\n",
      "Cbc0038I Pass  22: (2786.14 seconds) suminf.   98.45565 (1382) obj. 0 iterations 259\n",
      "Cbc0038I Pass  23: (2802.95 seconds) suminf.   97.68706 (1437) obj. 0 iterations 517\n",
      "Cbc0038I Pass  24: (2841.87 seconds) suminf.   98.53350 (1374) obj. 0 iterations 753\n",
      "Cbc0038I Pass  25: (2961.49 seconds) suminf.  164.31686 (613) obj. 0 iterations 6582\n",
      "Cbc0038I Pass  26: (3012.08 seconds) suminf.  110.99102 (645) obj. 0 iterations 3576\n",
      "Cbc0038I Pass  27: (3026.07 seconds) suminf.  109.38181 (801) obj. 0 iterations 479\n",
      "Cbc0038I Pass  28: (3068.85 seconds) suminf.  100.61068 (1158) obj. 0 iterations 1440\n",
      "Cbc0038I Pass  29: (3083.69 seconds) suminf.   99.23436 (1259) obj. 0 iterations 489\n",
      "Cbc0038I Pass  30: (3104.86 seconds) suminf.   97.60646 (1373) obj. 0 iterations 505\n",
      "Cbc0038I Pass  31: (3125.61 seconds) suminf.   96.82529 (1418) obj. 0 iterations 367\n",
      "Cbc0038I Pass  32: (3137.74 seconds) suminf.   96.15287 (1396) obj. 0 iterations 286\n",
      "Cbc0038I Pass  33: (3161.85 seconds) suminf.   95.08950 (1459) obj. 0 iterations 585\n",
      "Cbc0038I Pass  34: (3189.79 seconds) suminf.   95.92149 (1413) obj. 0 iterations 677\n",
      "Cbc0038I Pass  35: (3209.85 seconds) suminf.   95.80709 (1415) obj. 0 iterations 430\n",
      "Cbc0038I Pass  36: (3544.58 seconds) suminf.  173.25207 (667) obj. 0 iterations 6774\n",
      "Cbc0038I Pass  37: (3585.75 seconds) suminf.  106.36023 (747) obj. 0 iterations 3495\n",
      "Cbc0038I Pass  38: (3621.07 seconds) suminf.  103.43350 (968) obj. 0 iterations 823\n",
      "Cbc0038I Pass  39: (3707.20 seconds) suminf.   98.70553 (1126) obj. 0 iterations 714\n",
      "Cbc0038I Pass  40: (3727.53 seconds) suminf.   97.96827 (1160) obj. 0 iterations 261\n",
      "Cbc0038I Pass  41: (3758.53 seconds) suminf.   94.22969 (1394) obj. 0 iterations 1019\n",
      "Cbc0038I Pass  42: (3787.96 seconds) suminf.   94.98094 (1342) obj. 0 iterations 532\n",
      "Cbc0038I Pass  43: (3827.78 seconds) suminf.   94.13564 (1405) obj. 0 iterations 497\n",
      "Cbc0038I Pass  44: (3919.86 seconds) suminf.   93.35909 (1454) obj. 0 iterations 417\n",
      "Cbc0038I Pass  45: (3955.04 seconds) suminf.   94.20519 (1396) obj. 0 iterations 862\n",
      "Cbc0038I Pass  46: (3975.80 seconds) suminf.   94.14023 (1412) obj. 0 iterations 359\n",
      "Cbc0038I Pass  47: (4281.36 seconds) suminf.  163.78652 (643) obj. 0 iterations 7139\n",
      "Cbc0038I Pass  48: (4364.84 seconds) suminf.  106.71864 (812) obj. 0 iterations 3511\n",
      "Cbc0038I Pass  49: (4371.58 seconds) suminf.  105.95000 (864) obj. 0 iterations 243\n",
      "Cbc0038I Pass  50: (4408.44 seconds) suminf.   99.45951 (1134) obj. 0 iterations 1053\n",
      "Cbc0038I Pass  51: (4457.43 seconds) suminf.   97.37445 (1242) obj. 0 iterations 635\n",
      "Cbc0038I Pass  52: (4552.24 seconds) suminf.   95.06587 (1396) obj. 0 iterations 807\n",
      "Cbc0038I Pass  53: (4570.67 seconds) suminf.   94.47494 (1372) obj. 0 iterations 317\n",
      "Cbc0038I Pass  54: (4595.31 seconds) suminf.   93.40712 (1441) obj. 0 iterations 569\n",
      "Cbc0038I Pass  55: (4640.99 seconds) suminf.   94.27084 (1379) obj. 0 iterations 747\n",
      "Cbc0038I Pass  56: (4676.41 seconds) suminf.   94.28426 (1379) obj. 0 iterations 292\n",
      "Cbc0038I Pass  57: (4764.09 seconds) suminf.   95.05863 (1328) obj. 0 iterations 917\n",
      "Cbc0038I Pass  58: (4796.32 seconds) suminf.   94.22709 (1401) obj. 0 iterations 598\n",
      "Cbc0038I Pass  59: (4818.17 seconds) suminf.   94.25304 (1384) obj. 0 iterations 413\n",
      "Cbc0038I Pass  60: (5129.77 seconds) suminf.  162.18028 (555) obj. 0 iterations 7361\n",
      "Cbc0038I Pass  61: (5212.33 seconds) suminf.  111.53889 (533) obj. 0 iterations 3172\n",
      "Cbc0038I Pass  62: (5232.59 seconds) suminf.  109.10712 (708) obj. 0 iterations 475\n",
      "Cbc0038I Pass  63: (5250.87 seconds) suminf.  107.62760 (822) obj. 0 iterations 457\n",
      "Cbc0038I Pass  64: (5286.72 seconds) suminf.  101.95176 (1059) obj. 0 iterations 939\n",
      "Cbc0038I Pass  65: (5364.03 seconds) suminf.   98.40539 (1260) obj. 0 iterations 968\n",
      "Cbc0038I Pass  66: (5442.85 seconds) suminf.   95.99740 (1414) obj. 0 iterations 915\n",
      "Cbc0038I Pass  67: (5487.69 seconds) suminf.   96.81851 (1366) obj. 0 iterations 682\n",
      "Cbc0038I Pass  68: (5518.22 seconds) suminf.   95.99359 (1417) obj. 0 iterations 645\n",
      "Cbc0038I Pass  69: (5592.95 seconds) suminf.   96.83360 (1361) obj. 0 iterations 1155\n",
      "Cbc0038I Pass  70: (5630.48 seconds) suminf.   96.81196 (1378) obj. 0 iterations 455\n",
      "Cbc0038I Pass  71: (5677.19 seconds) suminf.   97.58145 (1325) obj. 0 iterations 688\n",
      "Cbc0038I Pass  72: (5706.22 seconds) suminf.   96.81694 (1362) obj. 0 iterations 429\n",
      "Cbc0038I Pass  73: (5730.94 seconds) suminf.   95.99622 (1415) obj. 0 iterations 402\n",
      "Cbc0038I Pass  74: (5829.37 seconds) suminf.   96.84428 (1354) obj. 0 iterations 1277\n",
      "Cbc0038I Pass  75: (5857.97 seconds) suminf.   96.81529 (1378) obj. 0 iterations 292\n",
      "Cbc0038I Pass  76: (5894.57 seconds) suminf.   97.63322 (1323) obj. 0 iterations 446\n",
      "Cbc0038I Pass  77: (5927.41 seconds) suminf.   96.81694 (1362) obj. 0 iterations 463\n",
      "Cbc0038I Pass  78: (5952.17 seconds) suminf.   95.99622 (1415) obj. 0 iterations 430\n",
      "Cbc0038I Pass  79: (6018.39 seconds) suminf.   96.83132 (1364) obj. 0 iterations 1226\n",
      "Cbc0038I Pass  80: (6036.50 seconds) suminf.   96.81529 (1378) obj. 0 iterations 405\n",
      "Cbc0038I Pass  81: (6070.36 seconds) suminf.   97.63322 (1323) obj. 0 iterations 671\n",
      "Cbc0038I Pass  82: (6102.16 seconds) suminf.   96.81694 (1362) obj. 0 iterations 471\n",
      "Cbc0038I Pass  83: (6159.44 seconds) suminf.   95.99622 (1415) obj. 0 iterations 425\n",
      "Cbc0038I Pass  84: (6229.28 seconds) suminf.   96.83562 (1361) obj. 0 iterations 1170\n",
      "Cbc0038I Pass  85: (6245.58 seconds) suminf.   96.81529 (1378) obj. 0 iterations 311\n",
      "Cbc0038I Pass  86: (6271.69 seconds) suminf.   96.83513 (1366) obj. 0 iterations 409\n",
      "Cbc0038I Pass  87: (6533.55 seconds) suminf.  167.98996 (627) obj. 0 iterations 7970\n",
      "Cbc0038I Pass  88: (6602.38 seconds) suminf.  108.27205 (749) obj. 0 iterations 3567\n",
      "Cbc0038I Pass  89: (6608.08 seconds) suminf.  107.55236 (802) obj. 0 iterations 254\n",
      "Cbc0038I Pass  90: (6644.50 seconds) suminf.   99.40623 (1164) obj. 0 iterations 1147\n",
      "Cbc0038I Pass  91: (6687.12 seconds) suminf.   96.87229 (1315) obj. 0 iterations 659\n",
      "Cbc0038I Pass  92: (6742.95 seconds) suminf.   95.97386 (1364) obj. 0 iterations 361\n",
      "Cbc0038I Pass  93: (6778.14 seconds) suminf.   95.15666 (1427) obj. 0 iterations 517\n",
      "Cbc0038I Pass  94: (6836.57 seconds) suminf.   95.95976 (1382) obj. 0 iterations 1205\n",
      "Cbc0038I Pass  95: (6869.17 seconds) suminf.   95.95003 (1393) obj. 0 iterations 366\n",
      "Cbc0038I Pass  96: (6887.61 seconds) suminf.   95.97382 (1390) obj. 0 iterations 204\n",
      "Cbc0038I Pass  97: (7117.26 seconds) suminf.  170.40888 (748) obj. 0 iterations 6826\n",
      "Cbc0038I Pass  98: (7175.43 seconds) suminf.  105.67936 (883) obj. 0 iterations 3558\n",
      "Cbc0038I Pass  99: (7182.51 seconds) suminf.  104.88657 (950) obj. 0 iterations 248\n",
      "Cbc0038I Pass 100: (7301.23 seconds) suminf.  162.22056 (585) obj. 0 iterations 5267\n",
      "Cbc0038I No solution found this major pass\n",
      "Cbc0038I Before mini branch and bound, 138668 integers at bound fixed and 0 continuous\n",
      "Cbc0038I Full problem 428440 rows 142800 columns, reduced to 137763 rows 4132 columns\n",
      "Cbc0038I Mini branch and bound did not improve solution (7309.99 seconds)\n",
      "Cbc0038I After 7310.05 seconds - Feasibility pump exiting - took 4334.15 seconds\n",
      "Cbc0031I 134 added rows had average density of 15.462687\n",
      "Cbc0013I At root node, 134 cuts changed objective from 0 to 0 in 10 passes\n",
      "Cbc0014I Cut generator 0 (Probing) - 0 row cuts average 0.0 elements, 0 column cuts (0 active)  in 605.567 seconds - new frequency is -100\n",
      "Cbc0014I Cut generator 1 (Gomory) - 869 row cuts average 565.6 elements, 0 column cuts (0 active)  in 31.804 seconds - new frequency is 1\n",
      "Cbc0014I Cut generator 2 (Knapsack) - 0 row cuts average 0.0 elements, 0 column cuts (0 active)  in 13.937 seconds - new frequency is -100\n",
      "Cbc0014I Cut generator 3 (Clique) - 0 row cuts average 0.0 elements, 0 column cuts (0 active)  in 0.091 seconds - new frequency is -100\n",
      "Cbc0014I Cut generator 4 (MixedIntegerRounding2) - 0 row cuts average 0.0 elements, 0 column cuts (0 active)  in 7.237 seconds - new frequency is -100\n",
      "Cbc0014I Cut generator 5 (FlowCover) - 0 row cuts average 0.0 elements, 0 column cuts (0 active)  in 0.635 seconds - new frequency is -100\n",
      "Cbc0014I Cut generator 6 (TwoMirCuts) - 597 row cuts average 69.8 elements, 0 column cuts (0 active)  in 36.061 seconds - new frequency is -100\n",
      "Cbc0014I Cut generator 7 (ZeroHalf) - 1331 row cuts average 23.6 elements, 0 column cuts (0 active)  in 4222.046 seconds - new frequency is -100\n",
      "Cbc0010I After 0 nodes, 1 on tree, 1e+50 best solution, best possible 0 (14215.47 seconds)\n",
      "Cbc0010I After 100 nodes, 57 on tree, 1e+50 best solution, best possible 0 (20118.48 seconds)\n",
      "Cbc0010I After 200 nodes, 113 on tree, 1e+50 best solution, best possible 0 (24126.47 seconds)\n",
      "Cbc0010I After 300 nodes, 164 on tree, 1e+50 best solution, best possible 0 (26798.51 seconds)\n",
      "Cbc0010I After 400 nodes, 219 on tree, 1e+50 best solution, best possible 0 (27897.98 seconds)\n",
      "Cbc0010I After 500 nodes, 276 on tree, 1e+50 best solution, best possible 0 (27964.79 seconds)\n",
      "Cbc0010I After 600 nodes, 330 on tree, 1e+50 best solution, best possible 0 (27993.73 seconds)\n",
      "Cbc0010I After 700 nodes, 380 on tree, 1e+50 best solution, best possible 0 (28037.82 seconds)\n",
      "Cbc0010I After 800 nodes, 429 on tree, 1e+50 best solution, best possible 0 (28073.30 seconds)\n",
      "Cbc0010I After 900 nodes, 478 on tree, 1e+50 best solution, best possible 0 (28117.60 seconds)\n",
      "Cbc0010I After 1000 nodes, 528 on tree, 1e+50 best solution, best possible 0 (28149.60 seconds)\n",
      "Cbc0004I Integer solution of 0 found after 184331 iterations and 1006 nodes (28151.45 seconds)\n",
      "Cbc0001I Search completed - best objective 0, took 184331 iterations and 1006 nodes (28153.53 seconds)\n",
      "Cbc0032I Strong branching done 3984 times (184727 iterations), fathomed 0 nodes and fixed 0 variables\n",
      "Cbc0035I Maximum depth 205, 0 variables fixed on reduced cost\n",
      "Cuts at root node changed objective from 0 to 0\n",
      "Probing was tried 10 times and created 0 cuts of which 0 were active after adding rounds of cuts (605.567 seconds)\n",
      "Gomory was tried 247 times and created 2895 cuts of which 0 were active after adding rounds of cuts (180.221 seconds)\n",
      "Knapsack was tried 10 times and created 0 cuts of which 0 were active after adding rounds of cuts (13.937 seconds)\n",
      "Clique was tried 10 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.091 seconds)\n",
      "MixedIntegerRounding2 was tried 10 times and created 0 cuts of which 0 were active after adding rounds of cuts (7.237 seconds)\n",
      "FlowCover was tried 10 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.635 seconds)\n",
      "TwoMirCuts was tried 10 times and created 597 cuts of which 0 were active after adding rounds of cuts (36.061 seconds)\n",
      "ZeroHalf was tried 10 times and created 1331 cuts of which 0 were active after adding rounds of cuts (4222.046 seconds)\n",
      "\n",
      "Result - Optimal solution found\n",
      "\n",
      "Objective value:                -0.00000000\n",
      "Enumerated nodes:               1006\n",
      "Total iterations:               184331\n",
      "Time (CPU seconds):             15176.61\n",
      "Time (Wallclock seconds):       28164.07\n",
      "\n",
      "Option for printingOptions changed from normal to all\n",
      "Total time (CPU seconds):       15178.95   (Wallclock seconds):       28167.09\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if gurobi_lp == True:\n",
    "    # lp_problem.setParam('TimeLimit', 600)\n",
    "    lp_problem.setParam('Symmetry', 2)\n",
    "    lp_problem.setParam('NormAdjust', 2)\n",
    "    # lp_problem.setParam('MIPFocus', 2)\n",
    "    # lp_problem.setParam('Presolve', 1)\n",
    "    \n",
    "    lp_problem.setParam(GRB.Param.MIPGap, 1.5)\n",
    "\n",
    "    # Optimize the model\n",
    "    lp_problem.optimize()\n",
    "\n",
    "    # Print results\n",
    "    if lp_problem.status == GRB.OPTIMAL:\n",
    "        print(\"Optimal solution found\")\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Optimal solution not found\")\n",
    "    \n",
    "else:\n",
    "    lp_problem.solve() # pulp.GLPK(msg=True)) #(pulp.COIN_CMD()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert variable values assigned by the model to an interpretable output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for the Meeting Optimization:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if gurobi_lp: \n",
    "    ## Pull Values ==1 ##\n",
    "    results_list = []\n",
    "\n",
    "    # Print the results\n",
    "    print('\\nResults for the Meeting Optimization:\\n')\n",
    "    for key, variable in seated_vars.items():\n",
    "        if variable.x == 1:\n",
    "            results_list.append(key)\n",
    "else:\n",
    "    results_list = []\n",
    "\n",
    "    # Print the results\n",
    "    print('\\nResults for the Meeting Optimization:\\n')\n",
    "    for key, variable in seated_vars.items():\n",
    "        if variable.value() == 1:\n",
    "            results_list.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary to store pair counts # \n",
    "main_pair_counts = {}\n",
    "for pair in pair_count_list:\n",
    "    main_pair_counts[pair] = 0\n",
    "    for session in main_sessions: \n",
    "        for group in main_group_assignments[f'Session {session}']:\n",
    "            assignments = main_group_assignments[f'Session {session}'][group]\n",
    "            if pair[0] in assignments and pair[1] in assignments:\n",
    "                main_pair_counts[pair] += 1\n",
    "main_pair_counts = {k: v for k, v in main_pair_counts.items() if v>0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_satisfied_groupB_pref_pairs = list(set([pair for pair in groupB_pref_pairs if pair in main_pair_counts.keys() or (pair[1], pair[0]) in main_pair_counts.keys()]))\n",
    "main_satisfied_groupA_pref_pairs =list(set([pair for pair in groupA_pref_pairs if pair in main_pair_counts.keys() or (pair[1], pair[0]) in main_pair_counts.keys()]))\n",
    "main_satisfied_mutual_pref_pairs = list(set([pair for pair in mutual_pref_pairs if pair in main_pair_counts.keys()  or (pair[1], pair[0]) in main_pair_counts.keys()]))\n",
    "main_satisfied_groupB_nopref_pairs = list(set([pair for pair in groupB_nopref_pairs if pair in main_pair_counts .keys() or (pair[1], pair[0]) in main_pair_counts.keys()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAIN\n",
      "0.0 % GroupA prefs satsified in Main\n"
     ]
    }
   ],
   "source": [
    "print('MAIN')\n",
    "if  len(groupB_pref_pairs) > 0:\n",
    "    print(round((len(set(main_satisfied_groupB_pref_pairs)) / len(groupB_pref_pairs) )*100, 2) , '% GroupB prefs satsified  in Main')\n",
    "if  len(groupA_pref_pairs) > 0:\n",
    "    print(round((len(set(main_satisfied_groupB_pref_pairs)) / len(groupA_pref_pairs))*100, 2) , '% GroupA prefs satsified in Main')\n",
    "if  len(mutual_pref_pairs) > 0:\n",
    "    print(round((len(set(main_satisfied_mutual_pref_pairs)) / len(mutual_pref_pairs))*100, 2) , '% Mutual prefs satsified in Main')\n",
    "# if  len(groupB_no_pref_pairs) > 0:\n",
    "#     print(round((len(set(main_satisfied_groupB_nopref_pairs)) / len(groupB_no_pref_pairs))*100, 2), '% No prefs satsified  in Main')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create dictionary with all values! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at pair counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_counts = {}\n",
    "\n",
    "for pair in pair_count_list:\n",
    "    \n",
    "    pair_counts[pair] = 0 \n",
    "    if pair in main_pair_counts:\n",
    "        pair_counts[pair] += main_pair_counts[pair]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 7021})"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(pair_counts.values())\n",
    "\n",
    "# print(f'{round((Counter(pair_counts.values())[1]*100 / Counter(pair_counts.values())[1]),1)}% of pairs sat together 1 time')\n",
    "# print(f'{round((Counter(pair_counts.values())[2]*100 / Counter(pair_counts.values())[1]),2)}% of pairs sat together 2 times')\n",
    "# print(f'{round((Counter(pair_counts.values())[3]*100 / Counter(pair_counts.values())[1]),3)}% of pairs sat together 3 times')\n",
    "# print(f'{round((Counter(pair_counts.values())[4]*100 / Counter(pair_counts.values())[1]),4)}% of pairs sat together 4 times')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Quality Check for pair counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sort the pair_counts so that they match up with the pair_count_list which creates all the table_session_pair_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_counts_sorted = {}\n",
    "for pair in pair_counts:\n",
    "    # if the inverse of the pair is in pair counts list swap them \n",
    "    if pair not in pair_count_list:\n",
    "        if (pair[1], pair[0]) in pair_count_list:\n",
    "            pair_counts_sorted[(pair[1], pair[0])] = pair_counts[pair]\n",
    "    elif pair in pair_count_list:\n",
    "        pair_counts_sorted[pair] = pair_counts[pair]\n",
    "\n",
    "pair_counts = pair_counts_sorted\n",
    "\n",
    "# sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check that the number of Group A  and Group B are correct for each\n",
    "- If youre looking at an old rerun it may be incorrect since the updated data determines the group frameworks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this might throw errors if the lunch session was run as a main session  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for session in main_sessions:\n",
    "\n",
    "    for group in range(1, number_groups_dict[session] + 1):\n",
    "        assignments = main_group_assignments[f'Session {session}'][group]\n",
    "        framework = group_frameworks[f'Session {session}'][f'Group {group}']\n",
    "        if framework.count('B') != sum(1 for item in assignments if item.endswith('_B')):\n",
    "            print('Session', session,'Group', group, 'GroupB')\n",
    "            print('Group Framework Count B:', (framework.count('B')),'Results Count B:', (sum(1 for item in assignments if item.endswith('_B'))) )\n",
    "        if framework.count('A') != sum(1 for item in assignments if item.endswith('_A')):\n",
    "            print('Session', session,'Group', group, 'GroupA')\n",
    "            print('Group Framework Count A:', (framework.count('A')),'Results Count A:', (sum(1 for item in assignments if item.endswith('_A'))) )\n",
    "        if framework.count('A') == sum(1 for item in assignments if item.endswith('_A')) and framework.count('A') == sum(1 for item in assignments if item.endswith('_A')):\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Are people seated more than one time in a session?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_session_to_list_of_lists(session_data):\n",
    "    result = []\n",
    "    for key, inner_dict in session_data.items():\n",
    "        names = [name for name in inner_dict.values() if isinstance(name, str)]\n",
    "        result.append(names)\n",
    "    return result\n",
    "\n",
    "# Create a Pandas Series\n",
    "for session in range(1, number_sessions+1):\n",
    "    df = pd.DataFrame(pd.Series([value for sublist in main_group_assignments[f'Session {session}'].values() for value in sublist]).value_counts()).reset_index()\n",
    "    df = df[df['index']!= 'Empty Seat']\n",
    "    if df[df['count'] >1].shape[0] >0:\n",
    "        to_print = df[df['count'] >1].shape[0]\n",
    "        raise ValueError(f'There are {to_print} names in Session {session} that are seated twice')\n",
    "    #     print(f'There are {(df[df['count'] >1].shape[0])} names in Session {session} that are seated twice')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
